import time
import pandas as pd
from difflib import SequenceMatcher
from typing import List, Dict, Any, Optional, Tuple
from tqdm import tqdm

from ..api.api_client import YMGalAPIClient
from ..data.data_processor import DataProcessor


class MatchingEngine:
    """åŒ¹é…å¼•æ“ï¼Œè´Ÿè´£äº§å“åŒ¹é…é€»è¾‘"""
    
    def __init__(self, api_client: YMGalAPIClient, data_processor: DataProcessor):
        self.api_client = api_client
        self.data_processor = data_processor
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """åˆ©ç”¨ ``difflib.SequenceMatcher`` è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ã€‚"""
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def match_bgm_products_and_save(
        self,
        input_file: str = "bgm_archive_20250525 (1).xlsx",
        output_file: str = "products_matched.xlsx",
        unmatched_file: str = "products_unmatched.xlsx",
        org_output_file: str = "organizations_info.xlsx"
    ) -> None:
        """
        è¯»å–åŸå§‹æ•°æ®Excel -> ç›®æ ‡å¹³å°æœç´¢åŒ¹é… -> å†™ç»“æœ
        æ”¯æŒ **æ–­ç‚¹ç»­è·‘** ï¼šå·²å¤„ç†è¿‡çš„åŸå§‹åç§°ä¼šè·³è¿‡ã€‚
        """
        # 1. è¯»å–åŸå§‹æºæ–‡ä»¶
        df_bgm = self.data_processor.read_bgm_data(input_file)
        
        product_names_cn: List[str] = df_bgm["ä¸­æ–‡å"].dropna().astype(str).tolist()
        
        # 2. åŠ è½½å·²å¤„ç†è¿‡çš„ ID (ç”¨äºæ–­ç‚¹ç»­è·‘)
        processed_ids = self.data_processor.get_processed_ids(output_file)

        # 3. åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶ & token
        if not self.api_client.initialize_token():
            print("æ— æ³•è·å– tokenï¼Œæµç¨‹ç»ˆæ­¢")
            return

        self.data_processor.init_excel(output_file)
        self.data_processor.init_org_excel(org_output_file)

        # 4. åŠ è½½å·²æœ‰å…¬å¸ä¿¡æ¯åˆ°å†…å­˜ï¼Œé¿å…é‡å¤æŸ¥è¯¢
        processed_orgs = self.data_processor.get_processed_orgs(org_output_file)

        # 5. éå†åŸå§‹æ•°æ®è¡Œå¹¶åŒ¹é…
        for idx, row in tqdm(df_bgm.iterrows(), total=len(df_bgm), desc="å¤„ç†äº§å“"):
            bgm_id = str(row['id']) if 'id' in row and pd.notna(row['id']) else f"ROW_{idx}"
            
            if bgm_id in processed_ids:
                continue

            jp_name = str(row["æ—¥æ–‡å"]).strip() if pd.notna(row["æ—¥æ–‡å"]) else ""
            cn_name = str(row["ä¸­æ–‡å"]).strip() if pd.notna(row["ä¸­æ–‡å"]) else ""

            if not jp_name and not cn_name:
                self.data_processor.append_unmatched_to_excel(f"ID_{bgm_id}_ç©ºåç§°", unmatched_file)
                continue

            best_match = None
            best_score = -1.0  # åˆå§‹åŒ–æœ€é«˜å¾—åˆ†
            match_source = ""

            # å°è¯•åŒ¹é…æ—¥æ–‡å
            if jp_name:
                jp_matches = self.api_client.search_ym_top_matches(jp_name)
                if jp_matches and jp_matches[0]["score"] > best_score:
                    best_match = jp_matches[0]
                    best_score = best_match["score"]
                    match_source = "æ—¥æ–‡å"

            # å°è¯•åŒ¹é…ä¸­æ–‡å
            if cn_name:
                cn_matches = self.api_client.search_ym_top_matches(cn_name)
                if cn_matches and cn_matches[0]["score"] > best_score:
                    best_match = cn_matches[0]
                    best_score = best_match["score"]
                    match_source = "ä¸­æ–‡å"

            if best_match:
                row_list: List[Dict[str, Any]] = []
                # ---- å…¬å¸ä¿¡æ¯å¤„ç† ----------------------------------------
                org_id = str(best_match.get("orgId", ""))
                org_info = None  # type: Optional[Dict[str, Any]]

                if org_id:
                    should_retry = False
                    if org_id in processed_orgs:
                        # ä¿¡æ¯ä¸å®Œæ•´æ—¶é‡è¯• (æœ€å¤š 3 æ¬¡)
                        existing = processed_orgs[org_id]["info"]
                        if not existing.get("website") or not existing.get("description"):
                            should_retry = True
                            processed_orgs[org_id]["retry_count"] += 1
                    else:
                        should_retry = True
                        processed_orgs[org_id] = {"info": {}, "retry_count": 1}

                    if should_retry and processed_orgs[org_id]["retry_count"] <= 3:
                        org_info = self.api_client.get_organization_details(org_id)
                        if org_info:
                            processed_orgs[org_id]["info"] = org_info
                            self.data_processor.append_org_to_excel(org_info, org_output_file)
                    else:
                        org_info = processed_orgs[org_id]["info"]

                # ---- ç»„è£…è¡Œæ•°æ® -----------------------------------------
                row_data = {
                    "bgm_id": bgm_id,
                    "bgmäº§å“": jp_name if jp_name else cn_name, # ä½¿ç”¨éç©ºçš„åŸå§‹åç§°ä½œä¸ºbgmäº§å“
                    "name": best_match["name"],
                    "chineseName": best_match["chineseName"],
                    "ym_id": best_match["ym_id"],
                    "score": best_match["score"],
                    "orgId": org_id,
                    "orgName": (org_info or {}).get("name", best_match.get("orgName", "")),
                    "orgWebsite": (org_info or {}).get("website", best_match.get("orgWebsite", "")),
                    "orgDescription": (org_info or {}).get("description", best_match.get("orgDescription", "")),
                    "åŒ¹é…æ¥æº": match_source
                }
                row_list.append(row_data)

                self.data_processor.append_to_excel(row_list, output_file)
            else:
                self.data_processor.append_unmatched_to_excel(f"ID_{bgm_id}_æœªåŒ¹é…", unmatched_file)

            # é¿å…è§¦å‘æ¥å£é™æµ
            time.sleep(0.05)

        print("\næ‰€æœ‰åŒ¹é…ç»“æœå·²ä¿å­˜ã€‚ğŸ‰")
    
    def match_bgm_products_with_aliases_and_save(
        self,
        input_file: str = "ä¸»è¡¨_updated_processed_aliases_20250621_124012.xlsx",
        output_file: str = "products_matched.xlsx",
        unmatched_file: str = "products_unmatched.xlsx",
        org_output_file: str = "organizations_info.xlsx"
    ) -> None:
        """
        è¯»å–åŒ…å«åˆ«åçš„åŸå§‹æ•°æ®Excel -> ç›®æ ‡å¹³å°æœç´¢åŒ¹é… -> å†™ç»“æœ
        æ”¯æŒ **æ–­ç‚¹ç»­è·‘** ï¼šå·²å¤„ç†è¿‡çš„åŸå§‹åç§°ä¼šè·³è¿‡ã€‚
        """
        # 1. è¯»å–åŸå§‹æºæ–‡ä»¶
        df_bgm = self.data_processor.read_bgm_data_with_aliases(input_file)

        # 2. åŠ è½½å·²å¤„ç†è¿‡çš„ ID (ç”¨äºæ–­ç‚¹ç»­è·‘)
        processed_ids = self.data_processor.get_processed_ids(output_file)

        # 3. åˆå§‹åŒ–è¾“å‡ºæ–‡ä»¶ & token
        if not self.api_client.initialize_token():
            print("æ— æ³•è·å– tokenï¼Œæµç¨‹ç»ˆæ­¢")
            return

        self.data_processor.init_excel(output_file)
        self.data_processor.init_org_excel(org_output_file)

        # 4. åŠ è½½å·²æœ‰å…¬å¸ä¿¡æ¯åˆ°å†…å­˜ï¼Œé¿å…é‡å¤æŸ¥è¯¢
        processed_orgs = self.data_processor.get_processed_orgs(org_output_file)

        # 5. éå†åŸå§‹æ•°æ®è¡Œå¹¶åŒ¹é…
        for idx, row in tqdm(df_bgm.iterrows(), total=len(df_bgm), desc="å¤„ç†äº§å“"):
            bgm_id = str(row['bgm_id']) if 'bgm_id' in row and pd.notna(row['bgm_id']) else f"ROW_{idx}"

            if bgm_id in processed_ids:
                continue

            # åªç”¨åˆ«ååˆ—è¿›è¡ŒåŒ¹é…
            alias_cols = [col for col in row.index if col.startswith("åˆ«å")]
            aliases = [str(row[col]).strip() for col in alias_cols if pd.notna(row[col]) and str(row[col]).strip()]

            # 1. è·å–åŸå§‹åˆ†æ•°ï¼Œå¹¶ç¡®ä¿ä¸ºæµ®ç‚¹æ•°ï¼Œé»˜è®¤0
            original_score = 0.0
            if 'score' in row and pd.notna(row['score']):
                try:
                    original_score = float(row['score'])
                except (ValueError, TypeError):
                    pass # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œåˆ™ä¿æŒ0.0

            # 2. æŸ¥æ‰¾æ‰€æœ‰åˆ«åä¸­çš„æœ€ä½³åŒ¹é…
            best_match = None
            best_score = -1.0  # åˆå§‹åŒ–åˆ«ååŒ¹é…çš„æœ€é«˜åˆ†
            match_source = ""

            for i, alias in enumerate(aliases):
                matches = self.api_client.search_ym_top_matches(alias)
                if matches and matches[0]["score"] > best_score:
                    best_match = matches[0]
                    best_score = best_match["score"]
                    match_source = f"åˆ«å{i+1}"

            if best_match and best_score > original_score:
                row_list: List[Dict[str, Any]] = []
                # ---- å…¬å¸ä¿¡æ¯å¤„ç† (ä»…å½“åˆ«åæ›´ä¼˜æ—¶æ‰æŸ¥è¯¢) ----
                org_id = str(best_match.get("orgId", ""))
                org_info = None  # type: Optional[Dict[str, Any]]

                if org_id:
                    should_retry = False
                    if org_id in processed_orgs:
                        existing = processed_orgs[org_id]["info"]
                        if not existing.get("website") or not existing.get("description"):
                            should_retry = True
                            processed_orgs[org_id]["retry_count"] += 1
                    else:
                        should_retry = True
                        processed_orgs[org_id] = {"info": {}, "retry_count": 1}

                    if should_retry and processed_orgs[org_id]["retry_count"] <= 3:
                        org_info = self.api_client.get_organization_details(org_id)
                        if org_info:
                            processed_orgs[org_id]["info"] = org_info
                            self.data_processor.append_org_to_excel(org_info, org_output_file)
                    else:
                        org_info = processed_orgs[org_id]["info"]

                # ---- ç»„è£…æ–°è¡Œæ•°æ® ----
                row_data = {
                    "bgm_id": bgm_id,
                    "bgmäº§å“": row.get('bgmäº§å“') or row.get('åŸå§‹bgmäº§å“åç§°'),
                    "name": best_match["name"],
                    "chineseName": best_match["chineseName"],
                    "ym_id": best_match["ym_id"],
                    "score": best_score,
                    "orgId": org_id,
                    "orgName": (org_info or {}).get("name", best_match.get("orgName", "")),
                    "orgWebsite": (org_info or {}).get("website", best_match.get("orgWebsite", "")),
                    "orgDescription": (org_info or {}).get("description", best_match.get("orgDescription", "")),
                    "åŒ¹é…æ¥æº": match_source
                }
                row_list.append(row_data)
                self.data_processor.append_to_excel(row_list, output_file)
            else:
                # ---- ç»„è£…åŸå§‹è¡Œæ•°æ® ----
                row_data = {
                    "bgm_id": bgm_id,
                    "bgmäº§å“": row.get('bgmäº§å“') or row.get('åŸå§‹bgmäº§å“åç§°'),
                    "name": row.get('name'),
                    "chineseName": row.get('chineseName'),
                    "ym_id": row.get('ym_id'),
                    "score": original_score,
                    "orgId": row.get('orgId'),
                    "orgName": row.get('orgName'),
                    "orgWebsite": row.get('orgWebsite'),
                    "orgDescription": row.get('orgDescription'),
                    "åŒ¹é…æ¥æº": "åŸå§‹"
                }
                row_list = [row_data]
                self.data_processor.append_to_excel(row_list, output_file)

            # é¿å…è§¦å‘æ¥å£é™æµ
            time.sleep(0.001)

        print("\næ‰€æœ‰åŒ¹é…ç»“æœå·²ä¿å­˜ã€‚ğŸ‰")
    
    def match_target_with_source(
        self,
        target_file: str = "products_matched.xlsx",
        source_file: str = "processed_products_test5.xlsx",
        output_file: str = "target_source_matched.csv"
    ) -> None:
        """
        æŒ‰åç§°ç›¸ä¼¼åº¦å°† **ç›®æ ‡å¹³å°äº§å“** ä¸ **åŸå§‹äº§å“** å¯¹é½ï¼Œå¹¶è¾“å‡º CSV æ–‡ä»¶ã€‚
        """
        print("å¼€å§‹åŒ¹é…ç›®æ ‡å¹³å°äº§å“ä¸åŸå§‹äº§å“â€¦")

        # 1. è¯»å–ä¸¤ä¾§æ•°æ®
        target_df = pd.read_excel(target_file)
        source_df = pd.read_excel(source_file)

        results = []

        # 2. éå†ç›®æ ‡å¹³å°æ¡ç›®
        for _, target_row in target_df.iterrows():
            target_name = target_row["name"]
            target_cn_name = target_row["chineseName"]
            target_id = target_row["ym_id"]

            best_match, best_score = None, 0.0
            for _, source_row in source_df.iterrows():
                score = self.calculate_similarity(target_name, source_row["äº§å“åç§°"])
                if score > best_score:
                    best_match, best_score = source_row, score

            if best_match is not None and best_score >= 0.8:
                results.append({
                    "target_id": target_id,
                    "target_name": target_name,
                    "target_chinese_name": target_cn_name,
                    "source_id": best_match.get("äº§å“ID", ""),
                    "source_name": best_match["äº§å“åç§°"],
                    "source_score": best_match.get("è¯„åˆ†", ""),
                    "source_rank": best_match.get("æ’å", ""),
                    "source_votes": best_match.get("æŠ•ç¥¨æ•°", ""),
                    "source_summary": best_match.get("ç®€ä»‹", ""),
                    "match_score": round(best_score, 4)
                })
                print(f"åŒ¹é…æˆåŠŸï¼š{target_name} -> {best_match['äº§å“åç§°']} (å¾—åˆ†: {best_score:.4f})")

        pd.DataFrame(results).to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"\nåŒ¹é…ç»“æœå·²ä¿å­˜åˆ°ï¼š{output_file}  (å…± {len(results)} æ¡)")